## Cache与程序局部性原理
![image](https://pic1.zhimg.com/80/v2-a33f2f4c40034df001524ba8fb9c17f4_720w.jpg)

#### 局部性原理
略

#### 多级Cache结构
略

#### Cache分配策略（Cache Allocation Policy）
Cache分配策略是指：什么时候应该为数据分配cacheline
- 读分配：当CPU读数据时，发生cache miss，一般情况下会分配一个cache line并从主存中读取数据，cache一般都支持读分配
- 写分配：当CPU写数据发生miss时，才会考虑写分配，当不支持写分配时，写指令只会更新主存；当支持写分配时，先做读分配——从主存加载数据到cacheline，在更新cacheline中的数据。

#### Cache更新策略（Cache Update Policy）
cache更新策略是指：当发生cache命中时，写操作应该如何更新数据。
- 直写（Write Througn）：更新cache中数据的同时更新主存中的数据，cache和主存的数据始终保持一致。
- 回写（Write Back）：只更新cache中的数据，并且置位对应cacheline的一个dirty标志位。主存中的数据只有在cacheline被替换或者显式地clean时才会被更新。也就是cache和主存中的数据可能不一致，主存中的数据可能是修改前的，修改后的数据还在cache中。
- 直写的优势就在于始终保持cache和主存中的数据一致，实现简单；而写回需要考虑多种更复杂的情况（另开笔记学习）

## Cache映射方式
![image](https://pic4.zhimg.com/v2-ad47fa00875dcca7ea3e58b828edaeef_b.jpg)

高速缓存分为S个组，每个组有E行，每行有B个字节，Cache换入换出的最小单位为行。其中有效位用于标明该行是否有效，还有m-(b+s)个标记位tag用于唯一标识存储在该高速缓存行中的块。该缓存结构为==组相联高速缓存==，特别地：
- 当组数E=1时，称之为直接相联Cache；
- 当组数E=C/B时，此时S=1，称之为全相联Cache；

#### 直接相联Cache
对于直接相联Cache，块被精确地放到一个位置，优点在于硬件成本低，地址变换速度快，缺点在于：Cache存储空间得不到充分利用，容易产生Cache颠簸（Cache Thrashing，刚刚换进Cache的数据很快被换出）

#### 全相联Cache
对于全相联Cache，不需要Index部分，主存的块可以映射到Cache的任意一块，Cache利用率高，颠簸概率低，可以类比为停车时哪里都可以停，但找起车来就麻烦了，其电路设计比较困难，适合小容量Cache。

#### 组相联Cache
###### 路
引入路（Way）的概念，四路组相联就是将cache平均分为4份，每一个地址可以有4个cache line对应。计算实例：32KB大小的四路组相联，Cache line大小为32字节。共4路，则平均分后每路大小为8KB，Cache Line是32字节，因此一共有256组。于是：offset需要5位，index需要8位，剩余的就是tag位。

###### 优缺点
硬件成本相对更高，因为每次比较Tag需要多个Cache Line并行比较，但有助于降低Cache颠簸性。

###### 判断一个请求是否命中分为3步：
- 组选择：根据组索引Index直接匹配到某一组，这是直接映射；
- 行匹配：高速缓存行中的标记位Tag与每行相匹配，这是全相联；
- 字选择：b为表示块偏移，选择具体哪个字节。


## VIVT、VIPT、PIPT
#### Cache抽取的是物理地址还是虚拟地址？
根据标记域Tag和索引域Index可以分为下面3种：
- VIVT（Virtual Index Virtual Tag）
- VIPT（Virtual Index Physical Tag）
- PIPT（Physical Index Physical Tag）

不同Level的缓存，根据大小、效率要求可能会采取不同的虚拟/物理地址策略，但VIVT由于软件维护成本过高，现在不再采用这种方式。

#### 歧义问题ambiguity
- 相同的虚拟地址可能对应不同的物理地址，比如两个独立的进程就会出现这种问题，因为进程空间相互独立，采用VIVT的不同的数据在cache中具有相同的tag和index，于是就出现了歧义问题。
- 实例：进程A访问虚拟地址0x4000处的内存，结果是cache加载了0x2000处的内容；当切换到进程B时，进程B也访问0x4000处的内容，造成的结果是cache hit，读取到了错误的内容。
- 解决办法是OS在进程切换时flush缓存，这个OS带来了代理负担，并且会降低效率。而对于VIPT和PIPT的平台就不会存在这个问题，其flush函数是空的。

#### 别名问题alias
不同的虚拟地址可能映射到相同的物理地址，比如共享内存，在采用VIVT的平台中，同一个物理地址被加载到不同的cacheline，这会导致缓存不一致的问题。

#### VIVT
Cache在判断是否命中时使用的是虚拟地址，虚拟地址直接送到Cache控制器，如果cache hit则直接从cache中返回数据，若cache miss则将虚拟地址发往MMU，经过MMU转换成物理地址，再从主存中读取数据。这种缓存的优点在于设计简单，刚开始的CPU都是采用这种方式，但这种方式会引入很多软件使用上的问题：歧义与别名（见下），为了确保正确性，OS负责解决这些问题。==使用虚拟地址的Tag带来歧义问题，使用虚拟地址的Index带来别名问题。==

#### PIPT
![image](https://pic4.zhimg.com/80/v2-69fb9056736bae258ecfb10246fc1d77_720w.jpg)

也叫物理高速缓存，CPU发出的虚拟地址先经过MMU转换为物理地址，再发往Cache控制器。性能方面要差一些，因为先要经过地址翻译。但是软件层面上几乎不需要做任何维护。

#### VIPT
![image](https://pic4.zhimg.com/80/v2-12969d6792ebc4b5256e1822ffde6caf_720w.jpg)

物理标记的虚拟高速缓存，可以使用虚拟地址对应的Index去查找cache，与此同时将将虚拟地址发往MMU转换为物理地址，两者几乎同时完成，此时比较cacheline对应Tag和物理地址的Tag，以此判断是否hit。使用物理地址的Tag消除了歧义问题，但使用虚拟地址的Index仍然有可能带来别名问题，这要分情况讨论。

#### VIPT为什么消除了歧义问题？
以Linux 4KB页面为例，不考虑多级页表情况下，一个虚拟地址可以被分配两部分，[11:0]用作页内偏移，[31:12]用于页表项的索引。因此VIPT使用物理页大小的剩余位数作为Tag，而不是上述的index和offset的剩余位数。由于物理Tag是唯一的，因此不存在歧义。

#### VIPT的别名问题
- 在Linux系统中，页面大小为4KB，也就是说物理地址和虚拟地址的[11:0]是一样的，对于直接映射的cache而言，若大小小于4KB，则VIPT就等于PIPT，不会出现别名问题。
- 假设cache大小为8kB，则index来自于[12:x]（x取决于cacheline的大小），已知物理地址和虚拟地址的[11:x]是一样的，但是bit12却未必相等，这就导致可能出现别名问题。
- ==解决方法==：上述可知，别名问题出现在共享映射，需要想办法避免相同的物理地址加载到不同的cacheline中。Linux使用的方法是在建立共享映射时，返回的虚拟地址满足一路cache大小对齐，即可解决别名问题。（考虑上述例子，本来只能保证[11:x]VA和PA是一样的，当返回虚拟地址按8kB对齐后，bit12也能保证相同了）

#### VIPT和PIPT的选择
VIVT Cache问题太多，软件维护成本过高，是最难管理的高速缓存。所以现在基本只存在历史的文章中。现在我们基本看不到硬件还在使用这种方式的cache。现在使用的方式是PIPT或者VIPT。如果多路组相连高速缓存的一路的大小小于等于4KB，一般硬件采用VIPT方式，因为这样相当于PIPT，岂不美哉。当然，如果一路大小大于4KB，一般采用PIPT方式，也不排除VIPT方式，这就需要操作系统多操点心了。

## TLB是否拥有这些问题？
TLB本质上也是一块高速缓存，完成的是虚拟地址到物理地址的映射，因此TLB是一块虚拟高速缓存VIVT，既然是VIVT就有可能会出现歧义与别名。

#### 别名问题
回顾别名问题：多个虚拟地址对一个物理地址，但由于TLB的特殊性，对于单个进程而言，同一时间下一个虚拟地址对一个物理地址的映射是唯一的，==因此TLB不存在别名问题。==

#### 歧义问题
回顾歧义问题：一个虚拟地址对多个物理地址，这是可能的，在多个进程下，不同进程相同的虚拟地址可以映射到不同的物理地址。为了消除歧义，可以参考VIVT的解决办法，在进程切换时进行TLB flush（是整块TLB无效），但这样会使得切换后TLB大量miss，导致性能严重下降。

#### 尽量避免TLB flush：ASID
在TLB表项中引入ASID，Address Space ID，用于使TLB区分不同的进程，当进程切换时，进程A和进程B虽然虚拟地址是一样的，但由于ASID不同，不需要flush也避免了歧义问题。但这样需要软件来管理和分配ASID。Linux将ASID保存在task_struct中，进程切换时将ASID和页表基地址一起存放在页表基地址寄存器中，查找TLB时，将Tag和ASID一同进行比较，只有当两者都匹配，则为TLB hit.

#### 最后完善：nG
![image](https://pic2.zhimg.com/v2-80141749c349c85b28ee001e2d3f88c5_b.jpg)

内核空间和用户空间是分开的，且内核空间被所有进程所共享，因此进程A切换到进程B后，进程B需要访问内核空间时，实际上完全可以沿用进程A缓存的内核空间TLB，但是由于ASID不一致实际上会发生TLB miss.因此继续引入标志位nG用于标识是否为global映射（内核空间是global，用户空间是non-global）。如果是global映射，则不需要再去匹配ASID了。

#### 总结：什么时候应该flush TLB？
- ASID分配完时，需要flush所有的TLB表项，ASID可以由bitmap管理，flush TLB后将clear整个bitmap.
- 建立页表映射时，就需要flush该虚拟地址对应的表项（一项即可）。因为你不知道建立新映射A到C前，是否存在A到B的旧映射，所以统一在建立映射关系时flush TLB。