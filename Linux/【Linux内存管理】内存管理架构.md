## UMA与NUMA
#### UMA
Uniform Memory Access，一致存储器访问：物理存储器被所有处理器共享，所有处理器对内存具有相同的访问时间。缺点在与在SMP体系中，可伸缩性是有限的，当存储器和I/O接口达到饱和时，增加处理器的数量并不能获得更高的性能。

#### NUMA
Nonuniform Memory Access，非一致存储器访问：分布式的存储器访问方式，每个CPU被划分成结点node，每个结点具有自己的本地存储器空间，具有较快的访问速度，所有结点通过互联网络连接，当需要访问远处结点的存储空间时，将通过互联网络导致附加的时延。

#### Linux内存管理架构
Linux内核通过插入一些兼容层，将不同体系结构间具体实现的差异隐藏起来，提供对一致和非一致内存访问的相同数据结构和接口。

- NUMA架构中，处理器被划分成node，分配有本地存储器空间；
- UMA架构中，相当于只是用了一个NUMA结点，完成了同一的内存管理

## Linux内存管理的组织形式
Linux把物理内存划分为3个层次进行管理
![image](https://pic2.zhimg.com/80/v2-5082cfdf3acf48c18739a0da3eddfedd_720w.jpg)

#### 存储结点node
CPU成多个结点，内存被分成簇，每个CPU对应一个本地物理内存，每个内存簇被认为是一个结点。

#### 管理区zone
每个物理内存节点node被划分为多个内存管理区域,用于表示不同范围的内存,内核可以使用不同的映射方式映射物理内存。

#### 页面page
内存被细分为多个页面帧,页面是最基本的页面分配的单位

## Node
Linux内核使用`pg_data_t`类型描述node，其中比较重要的字段有该结点的内存管理域、结点的内存页面、交换守护进程等等。

## Zone
为了解决实际计算机体系结构的诸多硬件限制，Linux内核对于不同区域的内存采用不同的管理方式和映射方式。具体地，使用了三种区：
- `ZONE_DMA`：用于执行DMA操作
- `ZONE_NORMAL`：正常能够用于映射的页
- `ZONE_HIGHMEM`：高端内存，不能永久映射到物理内存

对于x86_32体系，内存管理区分布如下：
![image](https://img-blog.csdn.net/20160831134445680)
![image](http://ilinuxkernel.com/wp-content/uploads/2011/09/091011_1614_Linux5.png)

- `ZONE_DMA`包含的页框可以由老式基于ISA的设备通过DMA使用；
- `ZONE_DMA`和`ZONE_NORMAL`包含内存的常规页框，将他们线性地映射到线性地址空间的第4个GB；
- 在具有大容量RAM的现代32位计算机中，CPU不能直接访问所有的物理内存，因为线性地址空间太小，内核空间只有1G，但却需要管理更大的物理内存，为此引入了高端内存的概念；在现代64位机中，线性地址空间暂时还远远超过系统的实际物理地址，因此`ZONE_HIGHMEM`总是空的。

#### 管理区结构`zone_t`
里面保存着内存使用状态信息，如page使用统计,未使用的内存区域，互斥访问的锁（LOCKS）等.

## 高端内存
#### 为什么需要高端内存
32位Linux将4GB的内存空间划分为内核空间和用户空间，其中内核空间为第4个GB：0xC0000000~0xFFFFFFFF，如果系统的物理内存大于1GB，就没有足够的内核线性地址来固定映射到全部物理内存和I/O空间了；x86平台中设置了一个经验值896MB，将前896MB的内核空间固定映射到物理内存，之后的内核空间不能够建立固定的映射，称为高端内存。

![image](https://img-blog.csdn.net/20160831143301132)

#### 核心思想
==借一段地址空间，建立临时地址映射，用完后释放，达到这段地址空间可以循环使用，访问所有物理内存。==

#### 高端内存映射的3种方式
内核将高端内存划分为3个部分：
- VMALLOC_START~VMALLOC_END：被vmalloc()函数分配的物理上不连续，但线性空间连续的高端内存空间；
- KMAP_BASE~FIXADDR_START：被kmap()用于永久映射；
- FIXADDR_START~4G：被kmap_atomic()函数用来临时映射高端物理内存
- 其他未用高端线性地址空间可以用来在系统初始化期间永久映射I/O地址空间。

###### 永久内核映射
- 建立永久内核映射可能阻塞当前进程，因此不能用于中断处理程序和可延迟函数
- 永久内核映射允许内核建立高端页框到内核地址空间的长期映射；
- `kmap()`函数用于建立永久内核映射，内核专门预留了一块线性地址空间PKMAP_BASE~FIXADDR_START，该空间和其他空间使用同样的页目录表，这个空间为4M大小，通过kmap()最多可以同时映射1024个页表，因此对于不使用的页表应该及时释放。

###### 临时内核映射
- 不阻塞进程，可以在中断处理程序和可延迟函数中使用；
- 使用`kmap_atomic()`建立临时内核映射，内核确保同一窗口不会被两个不同的控制路径所使用。每一次映射会导致以前的映射被覆盖，因此这是一种临时的映射。


## Page
页框的信息保存在一个类型为page的页描述符中，所有页描述符存放在`mem_map`全局数组中，其中比较重要的两个字段为：
- _count：页引用计数器，-1表示页空闲，大于或等于0表示分配给了一个或者多个进程。
- flags：描述页框状态的标志位，例如锁定、刚刚访问、被修改（脏的）等等

#### 保留的页框池
- 在多数情况下，请求页框时如果有足够的空闲内存可用则立即满足，否则将回收一些内存，并阻塞内核控制路径直到内存被释放；而当处理中断或执行临界区代码时，内核控制路径不能被阻塞，应该产生原子内存分配请求，原子请求不会被阻塞，也只会分配失败仅仅而已。
- 内核设法尽量减少这种原子内存请求不能满足的事件发生，因此保留了一个页框池，仅在内存不足时被使用。

#### 分区页框分配器
管理区分配器接收动态分配和释放的请求，该部分允许搜搜一个能满足一组连续页框内存的管理区，页框被“==伙伴系统==”来处理；为了达到更好的性能，一小部分页框保留在高速缓存中用于快速地满足对单个页框的分配请求（==每CPU页框高速缓存==）。常用的函数有：
`alloc_pages(gfp_mask, order)`、`alloc_page(gfp_mask)`等等。

## 伙伴系统
见【Linux内存管理】伙伴系统

## 每CPU页框高速缓存
所有每CPU高速缓存包含一些预先分配的页框，用于满足本地CPU发出的单一内存请求。

#### 冷热高速缓存
每个内存管理区和每个CPU提供了两个高速缓存：
- 热高速缓存：内核或者用户态==刚分配到页框后就开始写==，该页框所包含的内容很有可能还在CPU硬件cache中
- 冷高速缓存：如果该页框将被==用作DMA填充==，则使用冷高速缓存是更好的，因为不涉及CPU因此不会弄脏硬件cache。

内核使用两个位标监视冷热高速缓存的大小，当页框低于下界low，则将通过伙伴系统分配batch个页框进行补充，若高于high则将释放batch个页面到伙伴系统中。