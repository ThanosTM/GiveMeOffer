## 5、死锁
#### 构成死锁的必要条件
1. ==互斥==：每个资源要么已经分配给了一个进程，要么就是可用的
2. ==占有和等待==：已经得到了某个资源的进程可以再请求新的资源
3. ==不可抢占==：已经分配给一个进程的资源不能强制性地被抢占，只能被占有它的进程显式地释放
4. ==环路等待==：多个进程组成一条环路，环路中每个进程都在等待下一个进程所占有的资源

#### 处理方法
###### 鸵鸟策略
解决死锁的代价很高，不采取任何任务措施的鸵鸟策略能够获得更高的性能，例如Linux，Unix，Windows均采用忽略死锁的方式

###### 死锁检测和死锁恢复
- 不试图阻止死锁，而是当==检测到死锁发生时==，采取恢复措施。

- 恢复手段：利用抢占恢复、利用回滚恢复、通过杀死进程恢复

###### 死锁预防
在==程序运行之前==预防发生死锁

1. 破坏互斥条件：例如允许多个进程同时输出打印机，然而真正请求物理打印机的只有打印机守护进程
2. 破坏占有和等待条件：规定所有进程在开始执行前请求所需要的全部资源
3. 破坏不可抢占条件
4. 破坏环路等待：给资源统一编号，进程只能按照编号顺序来请求资源

###### 死锁避免
在==程序运行时==避免发生死锁

银行家算法：拒绝进入一个不安全的状态（不安全状态也未必一定能导致死锁）
1. 查找进程矩阵中是否存在一行小于等于目前可用资源向量，若不存在，则将发生死锁，状态不安全
2. 若找到这样一行，将该进程标记为终止，将已分配的资源加到可用资源向量A中
3. 重复以上两步，直到所有进程都可标记为终止，则状态是安全的。


## 6、虚拟内存
#### 传统存储管理方式特征
- 一次性：作业必须一次性装入内存，单个作业很大或者大量作业情况下，内存不足以支持程序的运行
- 驻留性：作业结束前程序所有内容驻留在内存中，被阻塞也是如此，造成内存资源的浪费

#### 存储器局部性原理
###### 时间局部性
- 最近执行过的指令或访问过的数据很有可能在不久的将来再次访问，典型原因是循环操作
- 通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。

###### 空间局部性
- 程序访问某个存储单元后，邻近的单元很有可能在不久的将来被访问，典型原因是指令顺序存放，数据簇聚存储
- 空间局部性通常使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现

#### 虚拟内存
###### 虚拟存储器
操作系统提供部分装入、请求调入、置换功能（对用户完全透明），给用户一种存在一个比实际物理内存大得多的存储器。大小由计算机地址结构决定，32位机的虚拟地址空间为4G。

###### 需要硬件支持
- 一定容量的内存和外存
- 页表机制（或段表）
- 中断机制（缺页中断）
- 地址变换结构，完成虚拟地址到物理地址的转换（MMU）

###### 页表机制
![image](https://pic1.zhimg.com/80/v2-d854c86f6e086ba0d510eea31555e340_720w.jpg)
- 状态位P：指示该页是否调入内存
- 访问字段A：最近一段时间的访问次数，或已有多长时间未被访问，供置换算法参考
- 修改位M：该页调入内存后是否被修改过
- 外存地址：物理块号

###### 缺页中断
- 缺页中断：所要访问的页面不在内存中，则将产生一个缺页中断，启动磁盘读写调入页面
- 过程：
1. 启动磁盘读，进程阻塞
2. 内存中有空闲块，则分配一个块，将调入的页装入该块，修改页表表项
3. 没有空闲块，淘汰某一页，若淘汰页有被修改过，则启动磁盘写，写入外存

- 作为中断的一种：保护CPU环境、分析中断原因、缺页中断处理程序、恢复CPU环境

![image](https://pic4.zhimg.com/80/v2-ec104001cf57b5c715cc641af0f6d053_720w.jpg)

###### 地址变换结构
![image](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F102004L08.jpg)

#### TLB
处理器引入MMU后，每次读取指令与数据访问需要访问两次内存：首先查询页表获得物理地址，然后访问物理地址读取指令或者数据。而TLB，Translation Lookaside Buffer，是页表的Cache。

###### TLB表项
![image](https://img-blog.csdn.net/20140527122736656?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpc2hhbmd3ZW4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

标识（虚拟地址的一部分）、数据（物理页号）、辅助信息（存储保护信息等）

###### 映射方式
- ==全相连==：一个TLB表项可以与任意地址的页表项关联，利用率最大，但延迟也很大（需要逐一匹配完所有的表项），适合小容量TLB
- ==直接匹配==：每一个地址块可以通过模运算得到唯一TLB表项，效率高但命中率低
- ==组相连==：一种折中，分成若干组，组间采用直接匹配，组内采用全相连。实践表明8路（组内长度）仿佛是一个性能临界点，超过8路组内对比延迟带来的缺点就大于命中率提升带来的好处了

###### TLB表项更新：可硬件自动发起，也可软件主动更新
- TLB miss后，CPU从内存获取页表项，自动更新TLB表项
- TLB表项在某些情况下是无效的，例如进程切换、内核修改页表（CPU硬件是不知道TLB表项的有效性的），只能软件手动修改

#### 页面置换算法
当需要调入页面时，没有空闲的内存空间时，需要选择一个淘汰页，送入磁盘的对换区。一个好的对换算法具有较低的页面更换频率

###### 最佳置换算法OPT
选择淘汰以后永久不用的，或者最长时间内不使用的页面进行对换。但是无法预知进程中哪个页面以后是最长时间不使用的，故==无法实现==。

###### 先进先出页面置换算法
实现简单，只需要将调入的页面根据先后次序链接成队列。但与进程实际运行的规律不适应，因为在进程中，有些页面实际上经常被访问。

###### 最近最久未使用LRU置换算法
利用局部性原理，认为：过去一段时间未访问过的页面，在最近的将来也很有可能不会被访问。但需要记录并更新页面访问时间，==难以实现==。

###### CLOCK置换算法：试图以较小的开销接近LRU的性能
- 每个页面增加一个使用位R（硬件自动置位），选择淘汰页是是1清0并继续扫描，是0则淘汰该页——“再给一次机会”

- 问题：缺页实际上很少，R为都是1，CLOCK算法将退化为FIFO算法

###### 改进的CLOCK算法
- 再增加一个扫描指针用于定时清除R位，移动速度要快（相对于页面淘汰指针，类似CLOCK的分针）

- 增加一个修改位：首选没有修改过的位，因为修改过的位在替换之前必须写回，这样做可以节省时间
1. 首先扫描遇到(0,0)的页用于替换，扫描过程中不做任何修改
2. 没有找到(0,0)则选择(0,1)的，这个过程中使用位置0
3. 没有找到(0,1)的，回到原位置，所有使用位置0重复(1)步

#### 页面颠簸
最糟糕的情形，刚刚换出的页面马上又要换入内存，刚刚换入的马上又要换出，进程用于换页的时间多于执行时间。

#### 从何处调入页面
请求分页系统中的外存分为两部分：用于存放文件的文件区和用于存放对换页面的对换区。对换区通常是釆用连续分配方式，而文件区釆用离散分配方式，故对换区的磁盘I/O速度比文件区的更快。这样从何处调入页面有三种情况：
1. 系统拥有足够的对换区空间：可以全部从对换区调入所需页面，以提髙调页速度。为此，在进程运行前，需将与该进程有关的文件从文件区复制到对换区。
2. 系统缺少足够的对换区空间：凡不会被修改的文件都直接从文件区调入；而当换出这些页面时，由于它们未被修改而不必再将它们换出。但对于那些可能被修改的部分，在将它们换出时须调到对换区，以后需要时再从对换区调入。
3. UNIX方式：与进程有关的文件都放在文件区，故未运行过的页面，都应从文件区调入。曾经运行过但又被换出的页面，由于是被放在对换区，因此下次调入时应从对换区调入。进程请求的共享页面若被其他进程调入内存，则无需再从对换区调入。

## 7、分页与分段
#### 分页：物理内存友好型
- 页式存储管理是一种用户视角内存与物理内存相分离的内存分配管理方案，将程序的逻辑地址划分为固定大小的页，将物理内存划分为同样大小的不必连续的块
- 优点：没有外部碎片，但因为页内部空间可能填充不满而产生内部碎片

#### 分段：用户友好型
- 段氏存储管理将程序的地址空间划分为若干段，如代码段、数据段、堆栈段。每个进程有一个二维地址空间，相互独立，互不打扰。
- 优点：没有内部碎片，但因为段大小改变而产生外部碎片

#### 区别
###### 目的不同
分页是由于系统管理的需要，是信息的物理单位。分段是由于用户的需要，是信息的逻辑单位。
###### 大小不同
页的大小固定，由系统决定。段的大小不固定，由其完成的功能决定
###### 地址空间不同
页向用户提供一维地址空间，段向用户提供二维地址空间
###### 信息共享
页的保护和共享受到限制，段利于存储保护和信息共享
###### 内存碎片
分页没有外碎片，但有内碎片；分段没有内碎片，但有外碎片


## 8、堆和栈的区别
堆和栈实际上是操作系统对进程占用的内存空间的两种管理方式

#### 管理方式不同
栈由操作系统自动分配释放，堆的申请和释放由程序员控制，容易出现内存泄露

#### 空间大小不同
每个进程拥有的栈大小远远小于堆的大小，其中Windows默认进程栈大小为1Mb，Linux进程栈大小为8Mb

###### 修改Windows进程栈大小

增加编译选项，将进程栈修改为4Mb
```
gcc -Wl,--stack=4194304 test.c -o test
```

###### 修改Linux进程栈大小
Linux可以通过ulimit命令查看和修改进程栈上限值

```
ulimit -a 查看进程所有资源上限
ulimit -s xx 修改栈上限
```

同时在软件中也可以调用<sys/resource.h>中的API进行修改和查看
```
#include <sys/resource.h>
int getrlimit(int resource, struct rlimit *rlptr);
int setrlimit(int resource, const struct rlimit *rlptr);
```

###### 若分配超过进程栈大小将造成Segment Fault
测试程序：
```c
#include <stdio.h>

int main(){
    int array[1024*1024/2] = {1};
    printf("Hello, world");
    return 0;
} 
```

#### 生长方向不同
堆向上生长，栈向下生长

#### 分配效率不同
栈由操作系统自动分配，会在硬件层级对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是由C/C++提供的库函数或运算符来完成申请与管理，实现机制较为复杂，频繁的内存申请容易产生内存碎片，并且可能引发用户态和核心态的切换。显然，堆的效率比栈要低得多。

#### 存放内容不同
栈存放的内容，函数返回地址、相关参数、局部变量和寄存器内容等，而堆，一般情况堆顶使用一个字节的空间来存放堆的大小，而堆中具体存放内容是由程序员来填充的



